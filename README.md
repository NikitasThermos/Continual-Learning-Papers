# Continual Learning Papers


## Table of Contents
1. [Catastrophic Forgetting](#cf)
2. [Stability vs Plasticity](#svp)

<a name='cf'></a> 
## Catastrophic Forgetting 
* [Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem](https://www.sciencedirect.com/science/article/abs/pii/S0079742108605368) by Michael McCloskey, Neal J. Cohen. Psychology of Learning and Motivation Vol.24 (1989)
* [Virtual memories and Massive Generalization in Connectionist Combinatorial Learning](https://escholarship.org/uc/item/0dn8w2wb) by Brousse, O., & Smolensky, P. In Proceedings of the Annual Meeting of the Cognitive Science Society (Vol. 11)(1989).
* [Connectionist models of recognition memory: Constraints imposed by learning and forgetting functions](https://psycnet.apa.org/buy/1990-18992-001) by Ratcliff, Roger. Psychological Review, Vol 97(2)(1990)
* [Using Semi-Distributed Representations to Overcome Catastrophic Forgetting in Connectionlst Networks](https://cdn.aaai.org/Symposia/Spring/1993/SS-93-06/SS93-06-007.pdf) by French, R. M. In Proceedings of the 13th annual cognitive science society conference (Vol. 1, pp. 173-178)(1991).
* [Semi-distributed Representations and Catastrophic Forgetting in Connectionist Networks](https://www.tandfonline.com/doi/abs/10.1080/09540099208946624) by French, R. M. Connection Science, 4(3-4)(1992)
* [Catastrophic Interference is Eliminated in Pretrained Networks](https://www.researchgate.net/profile/Ken-Mcrae/publication/2418146_Catastrophic_Interference_is_Eliminated_in_Pretrained_Networks/links/0f3175322732b75ca9000000/Catastrophic-Interference-is-Eliminated-in-Pretrained-Networks.pdf) by McRae, K., & Hetherington, P. A.  In Proceedings of the 15h annual conference of the cognitive science society (Vol. 1, p. 2)(1993).
* [Catastrophic forgetting in connectionist networks](https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(99)01294-2?ref=https%3A%2F%2Fgithubhelp.com) by Robert M. French. Trends in cognitive sciences, 3(4)(1999)
* [An Empirical Investigation of Catastrophic Forgetting in Gradient-Based Neural Networks](https://arxiv.org/abs/1312.6211) by Goodfellow, I. J., Mirza, M., Xiao, D., Courville, A., & Bengio, Y. arXiv preprint(2013)
* [Measuring Catastrophic Forgetting in Neural Networks](https://ojs.aaai.org/index.php/AAAI/article/view/11651) by Kemker, R., McClure, M., Abitino, A., Hayes, T., & Kanan, C. In Proceedings of the AAAI conference on artificial intelligence (Vol. 32, No. 1)(2018).
* [An Empirical Study of Example Forgetting during Deep Neural Network Learning](https://arxiv.org/abs/1812.05159) by  Mariya Toneva, Alessandro Sordoni, Remi Tachet des Combes, Adam Trischler, Yoshua Bengio, Geoffrey J. Gordon. ICLR 2019
* [Localizing Catastrophic Forgetting in Neural Networks](https://arxiv.org/abs/1906.02568) by Wiewel, F., & Yang, B. arXiv preprint(2019)
* [Toward Understanding Catastrophic Forgetting in Continual Learning](https://arxiv.org/abs/1908.01091) by Nguyen, C. V., Achille, A., Lam, M., Hassner, T., Mahadevan, V., & Soatto, S.  arXiv preprint(2019). 
* [Sequential Mastery of Multiple Visual Tasks: Networks Naturally Learn to Learn and Forget to Forget](https://openaccess.thecvf.com/content_CVPR_2020/html/Davidson_Sequential_Mastery_of_Multiple_Visual_Tasks_Networks_Naturally_Learn_to_CVPR_2020_paper.html) by Guy Davidson, Michael C. Mozer.  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020
* [Understanding the Role of Training Regimes in Continual Learning](https://proceedings.neurips.cc/paper/2020/hash/518a38cc9a0173d0b2dc088166981cf8-Abstract.html?ref=https://githubhelp.com) by Seyed Iman Mirzadeh, Mehrdad Farajtabar, Razvan Pascanu, Hassan Ghasemzadeh. Advances in Neural Information Processing Systems, 33(2020) 
* [Continual Learning in Deep Networks: an Analysis of the Last Layer](https://arxiv.org/abs/2106.01834) by Lesort, T., George, T., & Rish, I. arXiv preprint(2021)
* [Architecture Matters in Continual Learning](https://arxiv.org/abs/2202.00275) by Seyed Iman Mirzadeh, Arslan Chaudhry, Dong Yin, Timothy Nguyen, Razvan Pascanu, Dilan Gorur, Mehrdad Farajtabar. arXiv preprint (2022)
* [Wide Neural Networks Forget Less Catastrophically](https://proceedings.mlr.press/v162/mirzadeh22a.html) by Mirzadeh, S. I., Chaudhry, A., Yin, D., Hu, H., Pascanu, R., Gorur, D., & Farajtabar, M.  In International Conference on Machine Learning(2022)  

<a name='svp'></a>
## Stability vs Plasticity
* [Memory retention – the synaptic stability versus plasticity dilemma](https://www.cell.com/trends/neurosciences/abstract/S0166-2236(04)00370-4) by Abraham, W. C., & Robins, A.Trends in neurosciences, 28(2)(2005)
* [The stability-plasticity dilemma: investigating the continuum from catastrophic forgetting to age-limited learning effects](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2013.00504/full) by Mermillod, M., Bugaiska, A., & Bonin, P. . Frontiers in psychology, 4, 504(2013).    

## Continual Learning Evaluation
* [Re-evaluating Continual Learning Scenarios: A Categorization and Case for Strong Baselines](https://arxiv.org/abs/1810.12488) by Hsu, YenChang, YenCheng Liu, Anita Ramasamy, and Zsolt Kira.Continual Learning Workshop. In 32nd Conference on Neural Information Processing Systems.(2018)
* [Towards Robust Evaluations of Continual Learning](https://arxiv.org/abs/1805.09733) by Farquhar, S., & Gal, Y. arXiv preprint(2018)  
* [Three scenarios for continual learning](https://arxiv.org/abs/1904.07734) by Van de Ven, G. M., & Tolias, A. S. arXiv preprint(2019)


## Continual Learning Surveys/Reviews
* [Continual lifelong learning with neural networks: A review](https://www.sciencedirect.com/science/article/pii/S0893608019300231) by Parisi, G. I., Kemker, R., Part, J. L., Kanan, C., & Wermter, S. Neural networks, 113 (2019)
* [Continual Learning with Neural Networks: A Review](https://dl.acm.org/doi/abs/10.1145/3297001.3297062) by Awasthi, A., & Sarawagi, S.  In Proceedings of the ACM India Joint International Conference on Data Science and Management of Data (2019)
* [Embracing Change: Continual Learning in Deep Neural Networks](https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-66132030219-9) by Hadsell, R., Rao, D., Rusu, A. A., & Pascanu, R. Trends in cognitive sciences, 24(12)(2020)
* [The Present and Future of Continual Learning](https://ieeexplore.ieee.org/abstract/document/9289549) by Bae, H., Song, S., & Park, J. In 2020 International Conference on Information and Communication Technology Convergence (ICTC)
* [A Continual Learning Survey: Defying Forgetting in Classification Tasks](https://ieeexplore.ieee.org/abstract/document/9349197) by De Lange, Matthias, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Aleš Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. IEEE transactions on pattern analysis and machine intelligence, 44(7)(2021)
* [Recent Advances of Continual Learning in Computer Vision: An Overview](https://arxiv.org/abs/2109.11369) by Qu, H., Rahmani, H., Xu, L., Williams, B., & Liu, J.arXiv preprint(2021) 
* [Continual Learning of Natural Language Processing Tasks: A Survey](https://arxiv.org/abs/2211.12701) by Ke, Z., & Liu, B. arXiv preprint(2022)
* [How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition](https://arxiv.org/abs/2207.07730) by Mendez, J. A., & Eaton, E. arXiv preprint(2022)
* [A Comprehensive Survey of Continual Learning: Theory, Method and Application](https://ieeexplore.ieee.org/abstract/document/10444954) by Wang, L., Zhang, X., Su, H., & Zhu, J. IEEE Transactions on Pattern Analysis and Machine Intelligence.(2024) 
